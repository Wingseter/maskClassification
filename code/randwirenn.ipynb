{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "# from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torchvision import datasets, transforms\n",
    "from torchviz import make_dot\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import networkx as nx\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import networkx as nx\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from zlib import crc32\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = './input/data/train/images'\n",
    "base_dir = './splitted'\n",
    "classes_list = [\"{0:02d}\".format(a) for a in range(18)]\n",
    "\n",
    "if not os.path.isdir(base_dir): \n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.isdir(train_dir): \n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.isdir(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "for classes in classes_list:\n",
    "    train_split = os.path.join(train_dir, str(classes))\n",
    "    if not os.path.isdir(train_split):\n",
    "        os.mkdir(train_split)\n",
    "    test_split = os.path.join(test_dir, str(classes))\n",
    "    if not os.path.isdir(test_split):\n",
    "        os.mkdir(test_split)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_is_this(data, file):\n",
    "    target = -1\n",
    "\n",
    "    # 마스크 여부 분류\n",
    "    if 'incorrect' in file:\n",
    "        target += 7\n",
    "    elif 'mask' in file:\n",
    "        target += 1\n",
    "    else: # not wear\n",
    "        target += 13\n",
    "\n",
    "    # 성별 분류\n",
    "    if data['gender'] == 'male':\n",
    "        target += 0\n",
    "    else: # female\n",
    "        target += 3\n",
    "\n",
    "    # 나이 분류\n",
    "    if data['age'] < 30:\n",
    "        target += 0\n",
    "    elif data['age'] >= 60:\n",
    "        target += 2\n",
    "    else: # 30 ~ 60\n",
    "        target += 1\n",
    "    \n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_splitter(identifier, test_ratio):\n",
    "    return crc32(np.string_(identifier)) & 0xffffffff < test_ratio * 2 ** 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_infos = pd.read_csv(\"./input/data/train/train.csv\")\n",
    "train_counter = {}\n",
    "test_counter = {}\n",
    "\n",
    "for i in range(18):\n",
    "    train_counter[str(i)] = 0\n",
    "    test_counter[str(i)] = 0\n",
    "\n",
    "for row in data_infos.iterrows():\n",
    "    data_num, data = row[0], row[1]\n",
    "\n",
    "    # 목표 디렉토리 설정\n",
    "    path = os.path.join(original_dataset_dir, data['path'])\n",
    "    # 디렉토리 리스트 가져오기\n",
    "    fnames = os.listdir(path)\n",
    "    # 데이터 분활하기\n",
    "    test_set_check = ratio_splitter(path, 0.15)\n",
    "    \n",
    "    for file in fnames:\n",
    "        if file[0] == '.':\n",
    "            continue\n",
    "\n",
    "        target_class = what_is_this(data, file)\n",
    "        target_path = \"{0:02d}\".format(target_class)\n",
    "        \n",
    "        src = os.path.join(path, file)\n",
    "\n",
    "        if test_set_check:\n",
    "            dst = os.path.join(os.path.join(test_dir, target_path), file)\n",
    "        else: # train_set\n",
    "            dst = os.path.join(os.path.join(train_dir, target_path), file)\n",
    "\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "        # 파일 확장자를 추출하기 위해서\n",
    "        name, extension = file.split(\".\") \n",
    "\n",
    "        if test_set_check:\n",
    "            change_name = os.path.join(os.path.join(test_dir, target_path), str(test_counter[str(target_class)]) + \".\" + extension)\n",
    "            test_counter[str(target_class)] += 1 \n",
    "        else: # train_set\n",
    "            change_name = os.path.join(os.path.join(train_dir, target_path), str(train_counter[str(target_class)]) + \".\" + extension)\n",
    "            train_counter[str(target_class)] += 1 \n",
    "            \n",
    "        shutil.move(dst, change_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_base = transforms.Compose([transforms.Resize([128, 86]),transforms.ToTensor()])\n",
    "normalize_calc = ImageFolder(root = \"./splitted/train\", transform = transform_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5602434 0.5241528 0.5015032\n",
      "0.2273327 0.23729324 0.24018635\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in normalize_calc]\n",
    "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in normalize_calc]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])\n",
    "meanG = np.mean([m[1] for m in meanRGB])\n",
    "meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])\n",
    "stdG = np.mean([s[1] for s in stdRGB])\n",
    "stdB = np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "print(meanR, meanG, meanB)\n",
    "print(stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanR, meanG, meanB = 0.5602434, 0.5241528, 0.5015032\n",
    "stdR, stdG, stdB = 0.2273327, 0.23729324, 0.24018635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transform = transforms.Compose([transforms.Resize([128, 86]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(list_of_epochs, list_of_train_losses, list_of_train_accuracies, list_of_val_accuracies):\n",
    "    plt.figure(figsize=(20, 9))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list_of_epochs, list_of_train_losses, label='training loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(list_of_epochs, list_of_train_accuracies, label='training accuracy')\n",
    "    plt.plot(list_of_epochs, list_of_val_accuracies, label='validation accuracy')\n",
    "    plt.legend()\n",
    "    if not os.path.isdir('./result_plots'):\n",
    "        os.makedirs('./result_plots')\n",
    "    plt.savefig('./result_plots/accuracy_plot_per_epoch.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lr(optim, epoch_num, lrate):\n",
    "    \"\"\"adjusts lr to starting lr thereafter reduced by 10% at every 20 epochs\"\"\"\n",
    "    lrate = lrate * (0.1 ** (epoch_num // 20))\n",
    "    for params in optim.param_groups:\n",
    "        params['lr'] = lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optim, loss_func, epoch_num, lrate):\n",
    "    model.train()\n",
    "    loop_iter = 0\n",
    "    training_loss = 0\n",
    "    training_accuracy = 0\n",
    "    for training_data, training_label in train_dataloader:\n",
    "        set_lr(optim, epoch_num, lrate)\n",
    "        training_data, training_label =\\\n",
    "            training_data.to(device), training_label.to(device)\n",
    "        optim.zero_grad()\n",
    "        pred_raw = model(training_data)\n",
    "        curr_loss = loss_func(pred_raw, training_label)\n",
    "        curr_loss.backward()\n",
    "        optim.step()\n",
    "        training_loss += curr_loss.data\n",
    "        pred = pred_raw.data.max(1)[1]\n",
    "\n",
    "        curr_accuracy =\\\n",
    "            float(pred.eq(training_label.data).sum()) * 100. / len(training_data) \n",
    "        training_accuracy += curr_accuracy\n",
    "        loop_iter += 1\n",
    "        if loop_iter % 100 == 0:\n",
    "            print(\n",
    "                f\"epoch {epoch_num}, loss: {curr_loss.data}, accuracy: {curr_accuracy}\")\n",
    "\n",
    "    data_size = len(train_dataloader.dataset) // batch_size\n",
    "    return training_loss / data_size, training_accuracy / data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_data_loader):\n",
    "    model.eval()\n",
    "    success = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data, test_label in test_data_loader:\n",
    "            test_data, test_label = test_data.to(device), test_label.to(device)\n",
    "            pred_raw = model(test_data)\n",
    "            pred = pred_raw.data.max(1)[1]\n",
    "            success += pred.eq(test_label.data).sum()\n",
    "\n",
    "    return float(success) * 100. / len(test_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(batch_size):\n",
    "    train_dataset = ImageFolder(root = \"./splitted/train\", transform = new_transform)\n",
    "    val_dataset = ImageFolder(root = \"./splitted/test\", transform = new_transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size= batch_size, shuffle=True, num_workers=4)\n",
    "    test_dataloader = DataLoader(val_dataset, batch_size= batch_size, shuffle = True, num_workers=4)\n",
    "    \n",
    "    return train_dataloader, test_dataloader\n",
    "train_dataloader, test_dataloader = load_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Class def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RndGraph(object):\n",
    "    def __init__(self, num_nodes, graph_probability, nearest_neighbour_k=4,\n",
    "                 num_edges_attach=5):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.graph_probability = graph_probability\n",
    "        self.nearest_neighbour_k = nearest_neighbour_k\n",
    "        self.num_edges_attach = num_edges_attach\n",
    "\n",
    "    def make_graph_obj(self):\n",
    "        graph_obj = nx.random_graphs.connected_watts_strogatz_graph(\n",
    "            self.num_nodes, self.nearest_neighbour_k, self.graph_probability)\n",
    "        return graph_obj\n",
    "\n",
    "    def get_graph_config(self, graph_obj):\n",
    "        incoming_edges = {}\n",
    "        incoming_edges[0] = []\n",
    "        node_list = [0]\n",
    "        last = []\n",
    "        for n in graph_obj.nodes():\n",
    "            neighbor_list = list(graph_obj.neighbors(n))\n",
    "            neighbor_list.sort()\n",
    "\n",
    "            edge_list = []\n",
    "            passed_list = []\n",
    "            for nbr in neighbor_list:\n",
    "                if n > nbr:\n",
    "                    edge_list.append(nbr + 1)\n",
    "                    passed_list.append(nbr)\n",
    "            if not edge_list:\n",
    "                edge_list.append(0)\n",
    "            incoming_edges[n + 1] = edge_list\n",
    "            if passed_list == neighbor_list:\n",
    "                last.append(n + 1)\n",
    "            node_list.append(n + 1)\n",
    "        incoming_edges[self.num_nodes + 1] = last\n",
    "        node_list.append(self.num_nodes + 1)\n",
    "        return node_list, incoming_edges\n",
    "\n",
    "    def save_graph(self, graph_obj, path_to_write):\n",
    "        if not os.path.isdir(\"cached_graph_obj\"):\n",
    "            os.mkdir(\"cached_graph_obj\")\n",
    "        #nx.write_yaml(graph_obj, \"./cached_graph_obj/\" + path_to_write)\n",
    "        with open(\"./cached_graph_obj/\" + path_to_write, 'w') as fh:\n",
    "            yaml.dump(graph_obj, fh)\n",
    "\n",
    "    def load_graph(self, path_to_read):\n",
    "        #return nx.read_yaml(\"./cached_graph_obj/\" + path_to_read)\n",
    "        with open(\"./cached_graph_obj/\" + path_to_read, 'r') as fh:\n",
    "            return yaml.load(fh, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randwire def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(layer):\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConv2d(nn.Module):\n",
    "    def __init__(self, input_ch, output_ch, kernel_length=3, dilation_size=1,\n",
    "                 padding_size=1, stride_length=1, bias_flag=True):\n",
    "        super(SepConv2d, self).__init__()\n",
    "        self.conv_layer = nn.Conv2d(input_ch, input_ch, kernel_length,\n",
    "                                    stride_length, padding_size, dilation_size,\n",
    "                                    bias=bias_flag, groups=input_ch)\n",
    "        self.pointwise_layer = nn.Conv2d(input_ch, output_ch, kernel_size=1,\n",
    "                                         stride=1, padding=0, dilation=1, \n",
    "                                         groups=1, bias=bias_flag)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise_layer(self.conv_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnitLayer(nn.Module):\n",
    "    def __init__(self, input_ch, output_ch, stride_length=1):\n",
    "        super(UnitLayer, self).__init__()\n",
    "\n",
    "        self.dropout = 0.3\n",
    "\n",
    "        self.unit_layer = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            SepConv2d(input_ch, output_ch, stride_length=stride_length),\n",
    "            nn.BatchNorm2d(output_ch),\n",
    "            nn.Dropout(self.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.unit_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNode(nn.Module):\n",
    "    def __init__(self, input_degree, input_ch, output_ch, stride_length=1):\n",
    "        super(GraphNode, self).__init__()\n",
    "        self.input_degree = input_degree\n",
    "        if len(self.input_degree) > 1:\n",
    "            self.params = nn.Parameter(torch.ones(\n",
    "                len(self.input_degree), requires_grad=True))\n",
    "        self.unit_layer = UnitLayer(\n",
    "            input_ch, output_ch, stride_length=stride_length)\n",
    "\n",
    "    def forward(self, *ip):\n",
    "        if len(self.input_degree) > 1:\n",
    "            op = (ip[0] * torch.sigmoid(self.params[0]))\n",
    "            for idx in range(1, len(ip)):\n",
    "                op += (ip[idx] * torch.sigmoid(self.params[idx]))\n",
    "            return self.unit_layer(op)\n",
    "        else:\n",
    "            return self.unit_layer(ip[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandWireGraph(nn.Module):\n",
    "    def __init__(self, num_nodes, graph_prob, input_ch, output_ch, train_mode,\n",
    "                 graph_name):\n",
    "        super(RandWireGraph, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.graph_prob = graph_prob\n",
    "        self.input_ch = input_ch\n",
    "        self.output_ch = output_ch\n",
    "        self.train_mode = train_mode\n",
    "        self.graph_name = graph_name\n",
    "\n",
    "        # get graph nodes and in edges\n",
    "        rnd_graph_node = RndGraph(self.num_nodes, self.graph_prob)\n",
    "        if self.train_mode is True:\n",
    "            print(\"train_mode: ON\")\n",
    "            rnd_graph = rnd_graph_node.make_graph_obj()\n",
    "            self.node_list, self.incoming_edge_list =\\\n",
    "                rnd_graph_node.get_graph_config(rnd_graph)\n",
    "            rnd_graph_node.save_graph(rnd_graph, graph_name)\n",
    "        else:\n",
    "            rnd_graph = rnd_graph_node.load_graph(graph_name)\n",
    "            self.node_list, self.incoming_edge_list =\\\n",
    "                rnd_graph_node.get_graph_config(rnd_graph)\n",
    "\n",
    "        # define input Node\n",
    "        self.list_of_modules = nn.ModuleList(\n",
    "            [GraphNode(self.incoming_edge_list[0], self.input_ch,\n",
    "                       self.output_ch, stride_length=2)])\n",
    "        # define the rest Node\n",
    "        self.list_of_modules.extend(\n",
    "            [GraphNode(self.incoming_edge_list[n], self.output_ch,\n",
    "                       self.output_ch) for n in self.node_list if n > 0])\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem_dict = {}\n",
    "        # start vertex\n",
    "        op = self.list_of_modules[0].forward(x)\n",
    "        mem_dict[0] = op\n",
    "\n",
    "        # the rest vertex\n",
    "        for n in range(1, len(self.node_list) - 1):\n",
    "            # print(node, self.in_edges[node][0], self.in_edges[node])\n",
    "            if len(self.incoming_edge_list[n]) > 1:\n",
    "                op = self.list_of_modules[n].forward(\n",
    "                    *[mem_dict[incoming_vtx] for incoming_vtx\n",
    "                      in self.incoming_edge_list[n]])\n",
    "            else:\n",
    "                op = self.list_of_modules[n].forward(\n",
    "                    mem_dict[self.incoming_edge_list[n][0]])\n",
    "            mem_dict[n] = op\n",
    "            \n",
    "        op = mem_dict[self.incoming_edge_list[self.num_nodes + 1][0]]\n",
    "        for incoming_vtx in range(\n",
    "            1, len(self.incoming_edge_list[self.num_nodes + 1])):\n",
    "            op += mem_dict[\n",
    "                self.incoming_edge_list[self.num_nodes + 1][incoming_vtx]]\n",
    "        return op / len(self.incoming_edge_list[self.num_nodes + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandWireNNModel(nn.Module):\n",
    "    def __init__(self, num_nodes, graph_prob, input_ch, output_ch, train_mode):\n",
    "        super(RandWireNNModel, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.graph_prob = graph_prob\n",
    "        self.input_ch = input_ch\n",
    "        self.output_ch = output_ch\n",
    "        self.train_mode = train_mode\n",
    "        self.dropout = 0.3\n",
    "        self.class_num = 18\n",
    "            \n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.output_ch,\n",
    "                      kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(self.output_ch),\n",
    "        )\n",
    "\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            RandWireGraph(self.num_nodes, self.graph_prob, self.input_ch,\n",
    "                          self.output_ch*2, self.train_mode, \n",
    "                          graph_name=\"conv_layer_2\")\n",
    "        )\n",
    "        self.conv_layer_3 = nn.Sequential(\n",
    "            RandWireGraph(self.num_nodes, self.graph_prob, self.input_ch*2,\n",
    "                          self.output_ch*4, self.train_mode, \n",
    "                          graph_name=\"conv_layer_3\")\n",
    "        )\n",
    "        self.conv_layer_4 = nn.Sequential(\n",
    "            RandWireGraph(self.num_nodes, self.graph_prob, self.input_ch*4,\n",
    "                          self.output_ch*8, self.train_mode, \n",
    "                          graph_name=\"conv_layer_4\")\n",
    "        )\n",
    "\n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.input_ch*8, out_channels=1280,\n",
    "                      kernel_size=1),\n",
    "            nn.BatchNorm2d(1280)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(1280, self.class_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.conv_layer_3(x)\n",
    "        x = self.conv_layer_4(x)\n",
    "        x = self.classifier_layer(x)\n",
    "\n",
    "        # global average pooling\n",
    "        _, _, h, w = x.size()\n",
    "        x = F.avg_pool2d(x, kernel_size=[h, w])\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "graph_probability = 0.7\n",
    "node_channel_count = 64\n",
    "num_nodes = 16\n",
    "lrate = 0.1\n",
    "train_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mode: ON\n",
      "train_mode: ON\n",
      "train_mode: ON\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 31.75 GiB total capacity; 30.34 GiB already allocated; 141.50 MiB free; 30.48 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13878/778938157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     training_loss, training_accuracy = train(rand_wire_model, train_dataloader,\n\u001b[0m\u001b[1;32m     18\u001b[0m                                              optim_module, loss_func, ep, lrate)\n\u001b[1;32m     19\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_wire_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13878/1497707895.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, optim, loss_func, epoch_num, lrate)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcurr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13878/869171882.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13878/3638195053.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# print(node, self.in_edges[node][0], self.in_edges[node])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincoming_edge_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 op = self.list_of_modules[n].forward(\n\u001b[0m\u001b[1;32m     45\u001b[0m                     *[mem_dict[incoming_vtx] for incoming_vtx\n\u001b[1;32m     46\u001b[0m                       in self.incoming_edge_list[n]])\n",
      "\u001b[0;32m/tmp/ipykernel_13878/1515266739.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *ip)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13878/3537663457.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 31.75 GiB total capacity; 30.34 GiB already allocated; 141.50 MiB free; 30.48 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "rand_wire_model = RandWireNNModel(num_nodes, graph_probability,\n",
    "                   node_channel_count, node_channel_count, train_mode).to(device)\n",
    "\n",
    "optim_module = optim.SGD(rand_wire_model.parameters(), lr=lrate,\n",
    "                         weight_decay=1e-4, momentum=0.8)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "epochs = []\n",
    "test_accuracies = []\n",
    "training_accuracies = []\n",
    "training_losses = []\n",
    "best_test_accuracy = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for ep in range(1, num_epochs + 1):\n",
    "    epochs.append(ep)\n",
    "    training_loss, training_accuracy = train(rand_wire_model, train_dataloader,\n",
    "                                             optim_module, loss_func, ep, lrate)\n",
    "    test_accuracy = accuracy(rand_wire_model, test_dataloader)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    training_losses.append(training_loss.cpu())\n",
    "    training_accuracies.append(training_accuracy)\n",
    "    print('test acc: {0:.2f}%, best test acc: {1:.2f}%'.format(\n",
    "        test_accuracy, best_test_accuracy))\n",
    "\n",
    "    if best_test_accuracy < test_accuracy:\n",
    "        model_state = {\n",
    "            'model': rand_wire_model.state_dict(),\n",
    "            'accuracy': test_accuracy,\n",
    "            'ep': ep,\n",
    "        }\n",
    "        if not os.path.isdir('model_checkpoint'):\n",
    "            os.mkdir('model_checkpoint')\n",
    "        model_filename = \"ch_count_\" + str(node_channel_count) + \"_prob_\" +\\\n",
    "                          str(graph_probability)\n",
    "        torch.save(model_state,\n",
    "                   './model_checkpoint/' + model_filename + 'ckpt.t7')\n",
    "        best_test_accuracy = test_accuracy\n",
    "        plot_results(epochs, training_losses, training_accuracies,\n",
    "                     test_accuracies)\n",
    "    print(\"model train time: \", time.time() - start_time)\n",
    "\n",
    "print(rand_wire_model)\n",
    "torch.save(rand_wire_model, 'efficientnet.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_model_params(model_obj):\n",
    "    num_params = 0\n",
    "    for l in list(model_obj.parameters()):\n",
    "        l_p = 1\n",
    "        for p in list(l.size()):\n",
    "            l_p *= p\n",
    "        num_params += l_p\n",
    "    return num_params\n",
    "print(\"total model params: \", num_model_params(rand_wire_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model accuracy: 84.74025974025975%, last epoch: 20\n",
      "tensor([ 3,  0,  1, 15,  3,  4,  3,  1,  4,  3,  0,  0,  0,  0,  0,  3, 10,  7,\n",
      "         1,  4,  9,  3,  0,  1,  0,  4,  5,  0,  1,  4,  4,  4,  1,  4, 16,  4,\n",
      "        17,  3,  1,  3,  0,  7,  7,  9,  1,  4, 15, 17,  5,  1,  3,  4,  0,  3,\n",
      "         3,  4,  4,  3,  4,  4,  4,  0,  3,  4], device='cuda:0')\n",
      "tensor([ 3,  3,  0,  4,  5,  4,  1,  0,  3,  4,  0,  4,  0,  0,  4,  4,  0,  1,\n",
      "         6,  1, 15,  2,  1,  1,  0,  0,  0,  4,  6, 16,  4, 13,  4,  3,  9, 10,\n",
      "         4, 15, 15,  1,  3,  0,  3,  0, 16,  4, 16,  0,  6,  3,  4, 12,  0,  4,\n",
      "         0,  4,  3,  3,  3,  3, 16,  3,  9,  0], device='cuda:0')\n",
      "tensor([ 3,  4,  6,  1,  6,  4,  6,  1,  3,  3,  3, 12,  4,  0,  9,  0,  3,  4,\n",
      "        12,  4, 12,  3,  3,  4, 16, 10,  4,  4,  1, 13,  1,  4,  3, 13,  3,  1,\n",
      "         1,  1,  4, 16, 16, 13,  0,  4,  1, 16,  3,  3,  0,  6,  4,  4,  1,  1,\n",
      "         4,  0, 13, 10,  4,  4,  2,  3,  0,  4], device='cuda:0')\n",
      "tensor([ 1,  0,  4, 15,  4,  4, 16,  3, 13,  4,  7,  1,  0,  4, 13, 15,  3, 10,\n",
      "         5, 12,  3,  7, 16, 12,  4,  9,  4,  6, 13,  0,  1,  3,  3, 16,  4,  6,\n",
      "         3,  4,  4,  4,  3, 10,  4, 14, 10,  4,  3,  3, 16,  4,  4,  4, 16,  0,\n",
      "         2,  3,  4,  0,  3, 10, 12,  2,  1,  4], device='cuda:0')\n",
      "tensor([ 0,  4,  3,  3,  3,  4,  4,  4, 16, 10,  1, 15,  4,  0,  4,  0,  4,  4,\n",
      "         0,  6, 10, 15,  4,  9,  1,  3,  0,  0,  1,  0,  1,  9, 16,  0,  4,  1,\n",
      "         4,  4,  7,  4,  4, 16,  1,  1,  4,  1,  4,  4,  3,  5,  4,  4,  4,  4,\n",
      "        10,  4,  4,  1,  6,  0, 16,  4,  5,  0], device='cuda:0')\n",
      "tensor([ 3,  4,  4,  4,  0, 17,  4,  0, 15,  2,  4,  4,  4,  5,  3,  1,  1,  0,\n",
      "         0,  0,  0,  0,  4, 16,  3,  3,  0,  8, 10,  4,  4,  1, 12,  7, 16,  3,\n",
      "         4,  0, 12,  9,  3,  4,  1,  4,  3,  6, 10,  9,  4, 16, 10,  4,  4,  3,\n",
      "        13,  9,  1,  1,  4,  6,  0,  3, 16,  3], device='cuda:0')\n",
      "tensor([10, 16,  4,  4,  1,  9,  5,  4,  3,  4, 13, 16,  3, 14, 16,  0,  4,  4,\n",
      "         0,  1, 10,  0,  1,  1,  1,  4,  4, 16,  4,  6,  0, 15,  6,  4, 17,  4,\n",
      "         1,  0, 16, 15,  1,  3,  1, 13,  1,  5,  3, 10,  1,  4,  5,  1,  0,  9,\n",
      "         4,  0,  1,  1, 15,  2,  4,  7,  1,  6], device='cuda:0')\n",
      "tensor([16,  1, 10, 15,  0, 16, 10,  0,  1,  3, 16, 10,  4, 10,  5,  7,  6,  3,\n",
      "         4,  4,  0,  0,  3,  1,  0, 12,  0,  4,  5,  3,  3,  7,  4,  0,  0,  4,\n",
      "         4, 12,  0,  1, 10,  4,  4,  1,  1,  0, 13,  4,  3, 15,  3,  0,  1,  4,\n",
      "         3,  5,  4,  4, 10,  6, 11,  5,  4,  4], device='cuda:0')\n",
      "tensor([ 0,  3,  4,  1,  4, 17,  4,  0,  3,  1,  3, 15, 12,  1,  4,  0,  4,  0,\n",
      "        10,  0,  4,  9,  1,  3,  1, 12,  3,  4,  3,  3,  3,  4, 16,  4,  4,  0,\n",
      "         4,  1,  4, 10,  0,  0,  0,  3,  4, 10,  4,  3, 16, 10,  1,  3,  3,  1,\n",
      "         0,  0, 10, 13,  0,  3,  4,  9, 14,  1], device='cuda:0')\n",
      "tensor([16,  4,  4, 16,  4,  9, 16,  0,  4,  4,  0,  4, 16, 13, 12,  3,  3,  1,\n",
      "         4,  9,  3,  3,  0,  3, 15,  4, 12, 13,  4,  4,  4,  1, 13,  0,  3,  4,\n",
      "         0, 10,  0,  4,  1,  4,  4,  2, 15,  3, 10,  6,  4,  4,  0,  1,  0, 13,\n",
      "         3,  1, 16, 12,  4,  7,  6,  4,  3,  4], device='cuda:0')\n",
      "tensor([ 0,  4,  3,  4,  1,  4,  4,  0,  3,  3,  0,  3,  3,  4,  3,  1,  2,  4,\n",
      "        15,  4,  4,  0,  1,  4,  3,  3, 16,  3,  4,  8,  1, 16,  9,  4, 16,  1,\n",
      "         1,  1, 12,  9,  4,  3,  1, 10,  6,  4,  2,  1,  1,  3,  4, 16,  0, 16,\n",
      "         4,  4, 10,  2,  0,  3,  4,  4,  4, 16], device='cuda:0')\n",
      "tensor([ 4,  4,  1,  4,  4,  4,  0,  1, 16,  3,  3,  3,  5,  6,  4, 15,  0,  5,\n",
      "         3,  1,  3,  4,  7,  0,  3,  0, 12, 12,  7, 16,  4, 13,  7,  1, 16, 16,\n",
      "         1,  3,  3, 16,  5,  4,  6,  3,  9, 12,  4,  7,  4,  4,  4, 16,  3,  0,\n",
      "        10,  1, 16,  1, 16,  0,  4,  0,  4,  1], device='cuda:0')\n",
      "tensor([12, 10,  1,  1,  0, 16,  4,  1,  0,  4,  1,  4,  0,  4,  1,  4,  3,  3,\n",
      "         1,  0, 15,  1, 16,  4, 10,  4,  0,  4,  1, 16,  9,  0,  2,  0,  2,  3,\n",
      "         3,  4,  1, 12,  5,  4,  4, 12,  0,  4, 16,  4,  4, 12,  6,  9,  4, 13,\n",
      "        10,  4, 16,  0,  0, 10,  3,  3,  4,  0], device='cuda:0')\n",
      "tensor([ 0,  0,  4,  4,  3,  4, 10,  4,  3, 10, 15,  0,  3,  7, 15,  1, 15,  0,\n",
      "         4,  0,  4,  0,  6,  4,  4,  3, 10, 10,  0,  6,  1, 16,  1,  4,  9,  3,\n",
      "        11, 10,  3,  0,  4,  4,  1,  4,  3,  3,  0,  3,  1,  1, 16,  0,  0,  1,\n",
      "         4, 12,  6,  1,  6,  0,  4, 12,  4,  1], device='cuda:0')\n",
      "tensor([ 4,  4,  3,  0, 11, 17, 15,  4,  1, 13,  4, 10,  4,  4, 16, 14,  1,  1,\n",
      "         4,  4,  4, 10,  4, 16, 15, 15,  4, 16,  1,  9,  4,  1,  3,  7,  3,  1,\n",
      "        13,  1,  4, 12,  5,  6, 13,  3,  0,  7,  4,  3, 10,  5,  7,  6,  3, 10,\n",
      "         1,  7,  4, 12,  0,  8, 16,  4,  1,  3], device='cuda:0')\n",
      "tensor([ 1, 16, 13,  1, 16,  0, 13,  9, 16,  1, 12,  6,  0, 16,  4,  0, 10,  1,\n",
      "         3,  4, 14, 16,  7,  0,  3,  0, 12,  0,  3,  0,  3, 12,  0,  1,  0, 16,\n",
      "         4,  0,  4,  3, 10,  4, 15,  4, 10, 16, 16,  2,  1,  1,  5,  6,  4,  0,\n",
      "         0,  0, 16,  4,  4,  1,  3,  3,  1,  3], device='cuda:0')\n",
      "tensor([ 5,  4,  3,  1, 12, 12,  4,  4,  0,  4, 10,  0,  1, 10, 13,  4,  3,  4,\n",
      "         3,  4,  1,  3,  4,  3,  4,  6, 13,  4,  1, 12,  0, 10,  1,  0,  4, 11,\n",
      "         0,  3,  4,  0,  3,  3, 12, 12,  1,  3,  6, 10, 16,  4, 10,  4,  1,  4,\n",
      "        16,  1, 13,  3,  4,  0, 13, 16,  3,  3], device='cuda:0')\n",
      "tensor([ 1, 15,  0, 12,  3,  6,  0,  4,  6,  4,  0,  4,  1,  1,  1,  3,  9,  4,\n",
      "         0,  7,  1,  4, 12,  3,  3,  1,  4,  1, 12,  0,  0,  1,  4,  4, 16,  2,\n",
      "         1,  4,  4, 14,  0,  4,  0,  5, 16,  4,  4,  3,  0,  3,  3,  6,  4,  5,\n",
      "        13,  0,  3,  7,  0,  5,  3, 16,  4,  1], device='cuda:0')\n",
      "tensor([ 9,  0,  3,  3,  4,  0, 15,  3,  4,  0,  3,  4, 15,  4,  4,  3,  0,  0,\n",
      "         3,  4,  3, 12, 15, 13,  3,  3,  4,  4,  3,  0,  2,  4,  3,  4,  4,  1,\n",
      "         1, 13,  0,  0, 13,  3, 15,  0,  1,  3,  6,  0,  1, 10,  9,  0,  3,  3,\n",
      "        15,  4,  1,  3,  3,  9,  1, 15,  5,  0], device='cuda:0')\n",
      "tensor([ 1,  1,  4,  6,  4,  4,  0,  3,  4,  0,  0, 13,  3,  0, 12, 10,  1,  4,\n",
      "         4, 12,  1,  1,  0,  7,  0,  5,  0, 16,  0, 16,  3, 10,  3, 12, 15,  4,\n",
      "         4,  5,  5, 13,  4, 16,  0,  4,  0,  0,  4,  0, 12,  4,  4,  4,  0,  4,\n",
      "         1,  0,  1,  4,  3,  4,  3,  4,  3,  3], device='cuda:0')\n",
      "tensor([ 7, 16,  4,  1,  4,  3,  6,  0,  4,  4,  4,  1,  4,  4,  4,  1, 15, 16,\n",
      "         1,  3,  6, 16,  7,  4,  4, 16,  4,  0,  9,  4, 10,  4,  0,  3,  4,  3,\n",
      "         4,  4,  1,  4,  4,  3,  4,  3,  1,  3,  9,  4,  4, 15,  7, 16,  4,  4,\n",
      "         0,  9,  0,  1,  4,  1,  3,  6,  0, 15], device='cuda:0')\n",
      "tensor([ 0,  1,  7,  1, 10, 16,  3,  1,  1,  0,  0,  9,  0,  0,  3,  4, 10,  3,\n",
      "         9,  1,  0,  3,  9,  4,  4,  4,  1, 10, 12,  4, 12,  3,  4, 13,  0,  4,\n",
      "         4, 13,  4,  3,  4, 10,  4,  1, 15,  4,  4, 15,  4,  1,  4,  4, 16,  1,\n",
      "        16,  0,  0,  4,  7,  4,  0,  1,  5,  0], device='cuda:0')\n",
      "tensor([ 4,  1,  4,  0, 12,  1,  9,  9,  0,  0,  0, 15,  4,  4,  3, 12,  4,  0,\n",
      "        13, 10,  3,  4, 15,  5, 13,  4,  3,  4,  4,  9,  1,  3,  4,  0, 16, 16,\n",
      "         3,  3, 10,  4,  1, 13,  4,  4, 12,  4, 15,  1,  0,  4,  4,  1,  9,  4,\n",
      "         4,  2,  6,  4,  6,  0, 16,  0,  7,  0], device='cuda:0')\n",
      "tensor([ 3,  4,  4,  0,  0,  4,  7,  9,  0,  6,  1, 15,  3,  3,  4,  0, 13,  4,\n",
      "         9,  4,  0,  4,  1,  0,  1,  7,  3, 16,  4,  4,  4,  5,  4,  4,  2, 13,\n",
      "         4,  3,  1, 16,  1,  3, 16,  3,  1,  9, 16,  3,  4,  0, 10,  3,  9,  0,\n",
      "         3,  1,  0,  1,  0, 10, 12,  0, 15,  7], device='cuda:0')\n",
      "tensor([ 0,  4,  1,  6,  0,  1,  1, 16,  0,  0,  0,  4,  2, 16,  4, 12,  6,  0,\n",
      "         0,  4,  4,  6,  3,  4, 10,  9,  0,  3,  3,  0,  3, 13,  0,  9,  9,  6,\n",
      "         4,  3, 10,  0,  4,  3,  0,  0,  0,  1, 13,  1,  0, 10,  0, 15,  1,  1,\n",
      "         1,  0,  3,  3,  4, 16,  0,  1,  4,  4], device='cuda:0')\n",
      "tensor([ 6,  4, 16,  3,  4,  3,  4,  3,  4,  3, 16, 15,  1,  1,  4,  4,  3,  4,\n",
      "         3, 10,  4,  1,  3, 15,  4, 13, 15,  4,  4,  0, 15,  4,  6, 12,  0,  3,\n",
      "         7,  4,  4,  1,  1,  4,  3, 16, 15,  3,  6,  3,  1,  3,  6,  3,  1,  4,\n",
      "         4,  1,  0,  4,  3,  3,  0, 16,  3,  0], device='cuda:0')\n",
      "tensor([ 9,  9,  0,  4, 14,  0,  0,  4,  4, 10,  4,  0,  4,  3,  3,  0,  3,  3,\n",
      "         4,  8,  1,  0,  4,  1,  3,  0,  4,  1,  4, 12,  0,  4,  4,  4,  1,  4,\n",
      "         0, 13,  0,  0,  0,  3,  0,  2, 10,  0,  4,  7,  4,  0,  1, 12,  3,  4,\n",
      "         4,  4,  4, 14, 12, 10,  3, 16,  3,  3], device='cuda:0')\n",
      "tensor([ 4,  4,  4, 15,  3,  0,  0,  4,  6,  3, 10, 11,  0,  4, 10, 10,  3,  4,\n",
      "         4,  0,  1,  3, 15,  1,  4,  1,  3,  4,  0, 12,  4,  1,  1,  4,  3,  5,\n",
      "        15,  4,  3,  9,  0,  0, 10, 12,  4,  0,  4,  3,  5,  6,  3,  1,  9,  3,\n",
      "         4,  4,  1,  3,  3,  3,  6,  4, 10,  1], device='cuda:0')\n",
      "tensor([ 3,  1, 10,  0,  0, 10,  4,  4,  1,  3,  7,  3,  3, 12, 10,  4, 10,  6,\n",
      "         3,  6, 13,  1, 13,  4,  4,  4,  4, 16,  1,  9,  4,  4,  3, 15,  4,  4,\n",
      "         3, 13,  0,  4,  4,  0,  9,  0,  4, 15,  1,  3, 16, 10,  1, 16, 14,  4,\n",
      "         1,  4,  0,  6, 10,  1,  3,  3, 10,  3], device='cuda:0')\n",
      "tensor([ 1,  1,  4,  1,  1, 16,  7,  4,  3,  0,  4,  6,  5,  9,  3,  6,  4, 12,\n",
      "         4,  0,  1, 15,  1,  0,  5,  1,  4,  7,  3,  1,  9,  4,  7,  4,  6,  4,\n",
      "        13,  4, 12, 16,  0,  1, 15,  4, 15, 15,  4,  3,  0, 12,  3,  3,  6,  1,\n",
      "         0,  5, 15,  1,  3,  4,  3,  4,  0,  3], device='cuda:0')\n",
      "tensor([ 0,  0, 10,  0,  4,  4,  0, 15,  9,  3,  1,  1,  0,  4,  4, 10,  0,  4,\n",
      "         6, 16,  4,  9, 10,  0,  4,  1, 16,  1,  4, 10, 10,  0,  4,  4,  4, 13,\n",
      "        16,  1,  1,  0,  0,  0,  1,  0,  3,  3,  4,  1,  1,  3,  4, 13,  4,  1,\n",
      "         0,  4,  0,  3,  1, 16,  4,  4,  3,  4], device='cuda:0')\n",
      "tensor([ 7, 12,  4,  1, 16,  4,  7,  5,  4,  0,  4,  3,  4,  6,  4,  4,  0,  4,\n",
      "         0,  4,  4,  9,  1,  7,  1,  4,  6,  4,  0,  3,  3,  3,  3,  0,  3, 15,\n",
      "         4,  1, 15,  3,  9, 13,  0, 15,  4,  3, 12,  4,  9,  0,  4,  1,  1,  1,\n",
      "         0,  4, 12,  9,  3,  0,  1,  4,  1, 10], device='cuda:0')\n",
      "tensor([ 4,  1,  3,  0, 11,  3,  3,  4,  1, 17,  3,  3,  3,  4,  4,  1,  4,  9,\n",
      "        13,  3,  5, 13, 10,  3, 13, 12,  3,  0, 12,  0,  6,  3, 13,  1,  3,  3,\n",
      "         4,  4, 13,  0,  7, 12,  4,  1,  4,  0,  4,  4,  9,  9,  3,  4,  4,  0,\n",
      "         4,  1,  4,  3,  3,  0,  1,  1, 15,  7], device='cuda:0')\n",
      "tensor([12,  3,  1,  4,  3,  4, 16,  9, 10,  4,  4,  1,  1,  4,  4,  7, 13,  2,\n",
      "         0,  7,  0,  3, 10,  0,  4,  4,  0,  4,  4,  4,  3,  1,  0, 10,  0,  4,\n",
      "         4,  4,  1, 12,  0,  0,  4,  9,  0,  0,  2,  4,  4, 13,  4,  7,  0,  0,\n",
      "         1,  3,  3,  0,  3,  4,  0,  4,  0,  1], device='cuda:0')\n",
      "tensor([ 6,  0, 10, 15,  4,  6, 10,  3,  9,  4,  4, 10,  4,  5,  4,  4,  6,  0,\n",
      "         4,  4,  1, 10,  1,  5,  4, 10,  3,  1,  7,  4,  4, 10,  1,  4,  4,  7,\n",
      "         4,  4,  1,  0,  5,  4,  1,  3, 16,  1,  4,  3,  3,  4,  0,  4,  1,  6,\n",
      "         0,  3,  0, 10, 12, 12,  4,  7,  0,  4], device='cuda:0')\n",
      "tensor([16, 10,  0,  1,  3,  1,  0,  1,  4,  7,  5, 13, 12,  4,  3,  1,  7,  0,\n",
      "         3, 12,  6,  1, 10,  3,  1,  6,  9,  0,  4,  3,  1,  2,  4,  3,  3,  4,\n",
      "         3,  4,  1,  0,  4,  5,  1,  4,  6,  3,  1, 12, 10,  1,  4,  0,  3,  3,\n",
      "         3,  1,  4, 10,  4,  6,  4,  4,  7,  4], device='cuda:0')\n",
      "tensor([13,  3,  1,  0,  4,  4,  4, 15,  4,  7,  4,  7,  1,  7,  0,  4,  4,  1,\n",
      "         4,  1,  0,  4, 10, 10,  3,  3,  4, 16,  0,  4,  4,  3, 12,  4,  4,  5,\n",
      "         4,  3, 16,  7, 12, 13,  4, 10,  4,  0,  9,  1,  0,  3,  1,  1,  0,  1,\n",
      "         7,  1,  1,  3,  1, 13,  5,  6,  1, 11], device='cuda:0')\n",
      "tensor([ 0,  4,  0,  0,  1,  6,  1,  1,  4,  1, 17,  0,  0,  4,  4,  1, 10,  3,\n",
      "         4,  9, 16,  4,  4,  4,  9,  1,  9,  7,  4,  1,  4,  0, 12,  7,  4,  3,\n",
      "         0,  7,  4, 10,  3,  9, 16,  0,  3,  0,  3,  0,  1,  5,  0,  0,  4,  1,\n",
      "         3,  0,  4, 12,  4,  7, 16,  4, 13, 16], device='cuda:0')\n",
      "tensor([ 5,  7,  4, 16, 13,  1,  3, 15, 16,  2, 13,  3, 16,  4,  0,  0, 15, 15,\n",
      "         1,  3,  3,  4, 10,  4,  3,  4,  4,  3,  4,  1,  4,  1,  1, 16,  4, 13,\n",
      "         4, 10,  0,  4,  4,  4,  7,  1,  1, 15,  0,  4, 10,  9,  4,  7, 10,  0,\n",
      "         6,  2,  3,  4,  9, 11, 12,  3,  4,  4], device='cuda:0')\n",
      "tensor([ 0,  3,  3,  4, 13, 10,  9,  0, 11,  4,  4,  0,  4,  0,  3, 12, 10,  3,\n",
      "         3,  2,  7,  0, 10,  4, 10,  6,  0,  1,  4,  3,  4,  0,  3,  3,  1,  1,\n",
      "         4,  9,  5,  4,  0,  1,  4,  4,  4,  3,  4,  1,  1, 10,  4, 13,  7,  3,\n",
      "        10,  6,  4,  1,  4,  4, 10,  5,  4,  1], device='cuda:0')\n",
      "tensor([ 3,  7,  3,  3,  6,  1, 10,  4, 16,  1, 15, 10, 10, 16,  3,  9,  4, 16,\n",
      "         1,  4,  4,  0,  4,  3,  7,  7,  4,  0,  5, 10,  4,  1,  4,  4,  7, 10,\n",
      "         4, 13,  3, 10, 16,  0,  1,  0,  3,  4,  4,  3,  0,  9,  3,  4, 15,  6,\n",
      "         0,  0,  6,  4,  7, 16, 10,  1, 10,  4], device='cuda:0')\n",
      "tensor([ 0,  3, 13,  7,  4,  7,  4,  4,  3, 10, 15,  4,  4,  4, 14,  0, 16,  3,\n",
      "         4,  4,  4, 10,  1,  1,  3,  0,  9,  4,  4,  1,  4,  9,  7,  0,  3,  0,\n",
      "         1,  4,  0,  6,  6,  3,  0,  0, 16,  3,  1, 16,  4,  4,  4,  4,  0, 10,\n",
      "         4,  3,  4,  3, 16,  4,  4,  4, 15,  4], device='cuda:0')\n",
      "tensor([ 3,  4, 12,  9, 16,  4,  3,  1,  4,  0,  3, 12,  4,  4,  4,  0,  3,  1,\n",
      "         5, 16,  3,  4,  3,  4,  4,  4,  5,  0,  0,  6,  4, 16,  3,  0,  4, 16,\n",
      "         2,  9,  4,  1,  0, 17,  0,  4,  3,  3,  4,  4,  3,  1,  3,  3,  4,  4,\n",
      "         6,  0,  0,  3, 16,  9,  0,  2,  0,  3], device='cuda:0')\n",
      "tensor([12,  0,  0,  1,  4, 15,  4,  3,  1,  3,  0,  4, 16,  0,  3,  0,  3,  1,\n",
      "         0, 16], device='cuda:0')\n",
      "test accuracy: 84.5959595959596 %\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./model_checkpoint\"):\n",
    "    rand_wire_nn_model = RandWireNNModel(num_nodes, graph_probability, node_channel_count, node_channel_count,\n",
    "                                         train_mode=False).to(device)\n",
    "    model_filename = \"ch_count_\" + str(node_channel_count) + \"_prob_\" + str(graph_probability)\n",
    "    model_checkpoint = torch.load('./model_checkpoint/' + model_filename + 'ckpt.t7')\n",
    "    rand_wire_nn_model.load_state_dict(model_checkpoint['model'])\n",
    "    last_ep = model_checkpoint['ep']\n",
    "    best_model_accuracy = model_checkpoint['accuracy']\n",
    "    print(f\"best model accuracy: {best_model_accuracy}%, last epoch: {last_ep}\")\n",
    "\n",
    "    rand_wire_nn_model.eval()\n",
    "    success = 0\n",
    "    for test_data, test_label in test_dataloader:\n",
    "        test_data, test_label = test_data.to(device), test_label.to(device)\n",
    "        pred_raw = rand_wire_nn_model(test_data)\n",
    "        pred = pred_raw.data.max(1)[1]\n",
    "        print(pred)\n",
    "        success += pred.eq(test_label.data).sum()\n",
    "    print(f\"test accuracy: {float(success) * 100. / len(test_dataloader.dataset)} %\")\n",
    "\n",
    "else:\n",
    "    assert False, \"File not found. Please check again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "check_dir = './input/data/eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model accuracy: 84.74025974025975%, last epoch: 20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (252000) does not match length of index (12600)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_780/4246638515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ans'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# 제출할 파일을 저장합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \"\"\"\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    748\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (252000) does not match length of index (12600)"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(check_dir, 'info.csv'))\n",
    "image_dir = os.path.join(check_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform_test = transforms.Compose([transforms.Resize([128, 86]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset_test = TestDataset(image_paths, transform_test)\n",
    "\n",
    "loader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    shuffle=False\n",
    ")\n",
    "rand_wire_nn_model = RandWireNNModel(num_nodes, graph_probability, node_channel_count, node_channel_count,\n",
    "                                        train_mode=False).to(device)\n",
    "\n",
    "model_filename = \"ch_count_\" + str(node_channel_count) + \"_prob_\" + str(graph_probability)\n",
    "model_checkpoint = torch.load('./model_checkpoint/' + model_filename + 'ckpt.t7')\n",
    "rand_wire_nn_model.load_state_dict(model_checkpoint['model'])\n",
    "last_ep = model_checkpoint['ep']\n",
    "best_model_accuracy = model_checkpoint['accuracy']\n",
    "print(f\"best model accuracy: {best_model_accuracy}%, last epoch: {last_ep}\")\n",
    "\n",
    "rand_wire_nn_model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader_test:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred_raw = rand_wire_nn_model(test_data)\n",
    "        pred = pred_raw.data.max(1)[1]\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(check_dir, 'submission.csv'), index=False)\n",
    "print('inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "index = np.random.randint(0, len(image_paths))\n",
    "image = img.imread(image_paths[index])\n",
    "plt.title(\"label : %s\" % all_predictions[index])\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
