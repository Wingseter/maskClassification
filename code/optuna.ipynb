{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc7c008a350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print(DEVICE)\n",
    "BATCH_SIZE = 150\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanR, meanG, meanB = 0.5602434, 0.5241528, 0.5015032\n",
    "stdR, stdG, stdB = 0.2273327, 0.23729324, 0.24018635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.Resize([128, 86]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
    "    ]),\n",
    "    'test': transforms.Compose([transforms.Resize([128, 86]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3756, 1: 2697, 2: 4249, 3: 3175, 4: 3445, 5: 3395, 6: 4514, 7: 3239, 8: 5108, 9: 3810, 10: 4134, 11: 4074, 12: 4504, 13: 3244, 14: 5107, 15: 3810, 16: 4134, 17: 4074}\n",
      "{0: 642, 1: 575, 2: 391, 3: 485, 4: 640, 5: 420, 6: 774, 7: 693, 8: 473, 9: 582, 10: 768, 11: 504, 12: 758, 13: 694, 14: 473, 15: 582, 16: 768, 17: 504}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "data_dir = './splitted' \n",
    "image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x]) for x in ['train', 'test']} \n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "\n",
    "print(dict(Counter(image_datasets['train'].targets)))\n",
    "print(dict(Counter(image_datasets['test'].targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and inference routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_dataloader, optim, epoch):\n",
    "    model.train()\n",
    "    for b_i, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        pred_prob = model(X)\n",
    "        loss = F.nll_loss(pred_prob, y) # nll is the negative likelihood loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    success = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred_prob = model(X)\n",
    "            loss += F.nll_loss(pred_prob, y, reduction='sum').item()  # loss summed across the batch\n",
    "            pred = pred_prob.argmax(dim=1, keepdim=True)  # use argmax to get the most likely prediction\n",
    "            success += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "    loss /= len(test_dataloader.dataset)\n",
    "    \n",
    "    accuracy = 100. * success / len(test_dataloader.dataset)\n",
    "\n",
    "    print('\\nTest dataset: Overall Loss: {:.4f}, Overall Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        loss, success, len(test_dataloader.dataset), accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super(ConvNet, self).__init__()\n",
    "        num_conv_layers = trial.suggest_int(\"num_conv_layers\", 1, 4)\n",
    "        num_fc_layers = trial.suggest_int(\"num_fc_layers\", 1, 2)\n",
    "\n",
    "        self.layers = []\n",
    "        input_depth = 3  \n",
    "        for i in range(num_conv_layers):\n",
    "            output_depth = trial.suggest_int(f\"conv_depth_{i}\", 16, 64)\n",
    "            self.layers.append(nn.Conv2d(input_depth, output_depth, 3, 1))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            input_depth = output_depth\n",
    "        self.layers.append(nn.MaxPool2d(2))\n",
    "        p = trial.suggest_float(f\"conv_dropout_{i}\", 0.1, 0.4)\n",
    "        self.layers.append(nn.Dropout(p))\n",
    "        self.layers.append(nn.Flatten())\n",
    "\n",
    "        input_feat = self._get_flatten_shape()\n",
    "        for i in range(num_fc_layers):\n",
    "            output_feat = trial.suggest_int(f\"fc_output_feat_{i}\", 16, 64)\n",
    "            self.layers.append(nn.Linear(input_feat, output_feat))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            p = trial.suggest_float(f\"fc_dropout_{i}\", 0.1, 0.4)\n",
    "            self.layers.append(nn.Dropout(p))\n",
    "            input_feat = output_feat\n",
    "        self.layers.append(nn.Linear(input_feat, 18))\n",
    "        self.layers.append(nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "    \n",
    "    def _get_flatten_shape(self):\n",
    "        conv_model = nn.Sequential(*self.layers)\n",
    "        op_feat = conv_model(torch.rand(1, 3, 128, 86))\n",
    "        n_size = op_feat.data.view(1, -1).size(1)\n",
    "        return n_size\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    model = ConvNet(trial)\n",
    "    model = model.to(DEVICE)\n",
    "    opt_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-1, 5e-1, log=True)\n",
    "    optimizer = getattr(optim, opt_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(1, 3):\n",
    "        train(model, DEVICE, train_dataloader, optimizer, epoch)\n",
    "        accuracy = test(model, DEVICE, test_dataloader)\n",
    "        trial.report(accuracy, epoch)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-02 09:03:40,328]\u001b[0m A new study created in memory with name: mastering_pytorch\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [0/70469 (0%)]\t training loss: 2.896232\n",
      "\n",
      "Test dataset: Overall Loss: 1.5659, Overall Accuracy: 4848/10726 (45%)\n",
      "\n",
      "epoch: 2 [0/70469 (0%)]\t training loss: 1.489450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-02 09:15:34,261]\u001b[0m Trial 0 finished with value: 56.91776990490397 and parameters: {'num_conv_layers': 3, 'num_fc_layers': 1, 'conv_depth_0': 35, 'conv_depth_1': 39, 'conv_depth_2': 20, 'conv_dropout_2': 0.287293364348293, 'fc_output_feat_0': 34, 'fc_dropout_0': 0.3207117601152695, 'optimizer': 'Adadelta', 'lr': 0.22323407762068637}. Best is trial 0 with value: 56.91776990490397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset: Overall Loss: 1.2601, Overall Accuracy: 6105/10726 (57%)\n",
      "\n",
      "epoch: 1 [0/70469 (0%)]\t training loss: 2.885364\n",
      "\n",
      "Test dataset: Overall Loss: 2.8998, Overall Accuracy: 473/10726 (4%)\n",
      "\n",
      "epoch: 2 [0/70469 (0%)]\t training loss: 2.888412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-02 09:27:06,517]\u001b[0m Trial 1 finished with value: 4.4098452358754425 and parameters: {'num_conv_layers': 4, 'num_fc_layers': 2, 'conv_depth_0': 45, 'conv_depth_1': 42, 'conv_depth_2': 49, 'conv_depth_3': 33, 'conv_dropout_3': 0.2537383564520036, 'fc_output_feat_0': 19, 'fc_dropout_0': 0.15085856736304884, 'fc_output_feat_1': 25, 'fc_dropout_1': 0.2591035083759582, 'optimizer': 'RMSprop', 'lr': 0.1077661825098647}. Best is trial 0 with value: 56.91776990490397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset: Overall Loss: 2.9251, Overall Accuracy: 473/10726 (4%)\n",
      "\n",
      "epoch: 1 [0/70469 (0%)]\t training loss: 2.916198\n",
      "\n",
      "Test dataset: Overall Loss: nan, Overall Accuracy: 642/10726 (6%)\n",
      "\n",
      "epoch: 2 [0/70469 (0%)]\t training loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-02 09:38:33,605]\u001b[0m Trial 2 finished with value: 5.985455901547641 and parameters: {'num_conv_layers': 3, 'num_fc_layers': 1, 'conv_depth_0': 19, 'conv_depth_1': 33, 'conv_depth_2': 60, 'conv_dropout_2': 0.3512702175401138, 'fc_output_feat_0': 22, 'fc_dropout_0': 0.22061991800377206, 'optimizer': 'SGD', 'lr': 0.36930645133838735}. Best is trial 0 with value: 56.91776990490397.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dataset: Overall Loss: nan, Overall Accuracy: 642/10726 (6%)\n",
      "\n",
      "results: \n",
      "num_trials_conducted:  3\n",
      "num_trials_pruned:  0\n",
      "num_trials_completed:  3\n",
      "results from best trial:\n",
      "accuracy:  56.91776990490397\n",
      "hyperparameters: \n",
      "num_conv_layers: 3\n",
      "num_fc_layers: 1\n",
      "conv_depth_0: 35\n",
      "conv_depth_1: 39\n",
      "conv_depth_2: 20\n",
      "conv_dropout_2: 0.287293364348293\n",
      "fc_output_feat_0: 34\n",
      "fc_dropout_0: 0.3207117601152695\n",
      "optimizer: Adadelta\n",
      "lr: 0.22323407762068637\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"mastering_pytorch\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=2000)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"results: \")\n",
    "print(\"num_trials_conducted: \", len(study.trials))\n",
    "print(\"num_trials_pruned: \", len(pruned_trials))\n",
    "print(\"num_trials_completed: \", len(complete_trials))\n",
    "\n",
    "print(\"results from best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"accuracy: \", trial.value)\n",
    "print(\"hyperparameters: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        num_conv_layers = 3\n",
    "        num_fc_layers = 1\n",
    "\n",
    "        self.layers = []\n",
    "        input_depth = 3  \n",
    "        output_depth = 35\n",
    "        self.layers.append(nn.Conv2d(input_depth, output_depth, 3, 1))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        input_depth = output_depth\n",
    "        output_depth = 39\n",
    "        self.layers.append(nn.Conv2d(input_depth, output_depth, 3, 1))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        input_depth = output_depth\n",
    "        output_depth = 20\n",
    "        self.layers.append(nn.Conv2d(input_depth, output_depth, 3, 1))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        input_depth = output_depth\n",
    "\n",
    "        self.layers.append(nn.MaxPool2d(2))\n",
    "        p = 0.287293364348293\n",
    "        self.layers.append(nn.Dropout(p))\n",
    "        self.layers.append(nn.Flatten())\n",
    "\n",
    "        input_feat = self._get_flatten_shape()\n",
    "        output_feat = 34\n",
    "        self.layers.append(nn.Linear(input_feat, output_feat))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        p = 0.3207117601152695\n",
    "        self.layers.append(nn.Dropout(p))\n",
    "        input_feat = output_feat\n",
    "        self.layers.append(nn.Linear(input_feat, 18))\n",
    "        self.layers.append(nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "    \n",
    "    def _get_flatten_shape(self):\n",
    "        conv_model = nn.Sequential(*self.layers)\n",
    "        op_feat = conv_model(torch.rand(1, 3, 128, 86))\n",
    "        n_size = op_feat.data.view(1, -1).size(1)\n",
    "        return n_size\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.cross_entropy(output, target, reduction = \"sum\").item()\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "   \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_optuna(model, train_loader, val_loader, optimizer, num_epoches = 30):\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1, num_epoches + 1):\n",
    "        since = time.time()\n",
    "        train(model, train_loader, optimizer)\n",
    "        train_loss, train_acc = evaluate(model, train_loader)\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "\n",
    "        print('+-+-++-+-++-+-++-+-+ epoch {} +-+-++-+-++-+-++-+-+'.format(epoch))\n",
    "\n",
    "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))\n",
    "        print('val loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = ConvNet().to(DEVICE)\n",
    "optimizer = optim.Adadelta(model_base.parameters(), lr = 0.22323407762068637)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna = train_optuna(model_base, train_dataloader, test_dataloader, optimizer, num_epoches=EPOCH)\n",
    "torch.save(optuna, 'optuna.pt')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
